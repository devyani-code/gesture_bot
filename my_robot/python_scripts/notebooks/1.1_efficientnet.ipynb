{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D,Dropout,BatchNormalization\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4146 images belonging to 5 classes.\n",
      "Found 1034 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = 'data'\n",
    "IMAGE_DIR = f'../{DATA_DIR}/dataset'\n",
    "\n",
    "image_generator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=False,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    "    )\n",
    "\n",
    "data_train = image_generator.flow_from_directory(\n",
    "    IMAGE_DIR,\n",
    "    target_size=(128,128),\n",
    "    batch_size=256,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset = 'training'   \n",
    ")\n",
    "\n",
    "data_val = image_generator.flow_from_directory(\n",
    "    IMAGE_DIR,\n",
    "    target_size=(128,128),\n",
    "    batch_size=256,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset = 'validation'   \n",
    ")\n",
    "\n",
    "N_CLASSES = data_train.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMSIZE = (128,128,3)\n",
    "INPUT_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetuned_efficientnet(include_top=False):\n",
    "    base_model = EfficientNetB0(include_top=include_top,input_shape=IMSIZE,weights='imagenet')\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    if not include_top:\n",
    "        x = Dense(N_CLASSES, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 04:13:50.578043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 04:13:50.582892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 04:13:50.583152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 04:13:50.583943: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-09 04:13:50.584576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 04:13:50.584899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 04:13:50.585046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 04:13:51.067976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 04:13:51.068163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 04:13:51.068290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 04:13:51.068387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4660 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "efficient_model = finetuned_efficientnet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = data_train.labels\n",
    "\n",
    "plt.figure(\"countplot\",figsize=(10,6))\n",
    "sns.countplot(x=y.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_147653/3581207362.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = efficient_model.fit_generator(data_train,validation_data=data_val, epochs=500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 9.3258 - accuracy: 0.2287 - val_loss: 1.7455 - val_accuracy: 0.2002\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 6.2522 - accuracy: 0.2151 - val_loss: 1.6219 - val_accuracy: 0.1954\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 17s 1s/step - loss: 3.3201 - accuracy: 0.2308 - val_loss: 1.6094 - val_accuracy: 0.2002\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 2.2504 - accuracy: 0.2361 - val_loss: 1.6094 - val_accuracy: 0.2002\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 17s 1s/step - loss: 1.8424 - accuracy: 0.2385 - val_loss: 1.6094 - val_accuracy: 0.2002\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.7443 - accuracy: 0.2258 - val_loss: 1.6094 - val_accuracy: 0.2002\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.6761 - accuracy: 0.2308 - val_loss: 1.6094 - val_accuracy: 0.2031\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.6212 - accuracy: 0.2402 - val_loss: 1.6094 - val_accuracy: 0.2031\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.5942 - accuracy: 0.2484 - val_loss: 1.6094 - val_accuracy: 0.2031\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.5871 - accuracy: 0.2328 - val_loss: 1.6094 - val_accuracy: 0.2031\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.5659 - accuracy: 0.2465 - val_loss: 1.6094 - val_accuracy: 0.2031\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 17s 998ms/step - loss: 1.5741 - accuracy: 0.2547 - val_loss: 1.6094 - val_accuracy: 0.2031\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 17s 1s/step - loss: 1.5657 - accuracy: 0.2506 - val_loss: 1.6094 - val_accuracy: 0.2002\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 17s 995ms/step - loss: 1.5407 - accuracy: 0.2723 - val_loss: 1.6094 - val_accuracy: 0.2002\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 16s 964ms/step - loss: 1.5660 - accuracy: 0.2578 - val_loss: 1.6094 - val_accuracy: 0.2002\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 17s 990ms/step - loss: 1.5386 - accuracy: 0.2631 - val_loss: 1.6094 - val_accuracy: 0.2031\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 17s 981ms/step - loss: 1.5384 - accuracy: 0.2607 - val_loss: 1.6094 - val_accuracy: 0.2031\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 16s 963ms/step - loss: 1.5332 - accuracy: 0.2508 - val_loss: 1.6094 - val_accuracy: 0.1983\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 16s 1s/step - loss: 1.5193 - accuracy: 0.2728 - val_loss: 1.6095 - val_accuracy: 0.1983\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 16s 961ms/step - loss: 1.5223 - accuracy: 0.2699 - val_loss: 1.6095 - val_accuracy: 0.1983\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 17s 1s/step - loss: 1.5318 - accuracy: 0.2656 - val_loss: 1.6095 - val_accuracy: 0.1983\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.5193 - accuracy: 0.2721 - val_loss: 1.6095 - val_accuracy: 0.1954\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.5253 - accuracy: 0.2817 - val_loss: 1.6095 - val_accuracy: 0.1954\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.5259 - accuracy: 0.2820 - val_loss: 1.6095 - val_accuracy: 0.1954\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4983 - accuracy: 0.2781 - val_loss: 1.6095 - val_accuracy: 0.1954\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4950 - accuracy: 0.2964 - val_loss: 1.6095 - val_accuracy: 0.1954\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.5155 - accuracy: 0.2969 - val_loss: 1.6095 - val_accuracy: 0.1954\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.4857 - accuracy: 0.2829 - val_loss: 1.6096 - val_accuracy: 0.1954\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.5294 - accuracy: 0.2672 - val_loss: 1.6096 - val_accuracy: 0.1954\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4962 - accuracy: 0.2820 - val_loss: 1.6096 - val_accuracy: 0.1954\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4927 - accuracy: 0.2974 - val_loss: 1.6096 - val_accuracy: 0.1954\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4815 - accuracy: 0.2950 - val_loss: 1.6095 - val_accuracy: 0.1954\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4962 - accuracy: 0.2964 - val_loss: 1.6096 - val_accuracy: 0.1954\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4814 - accuracy: 0.2926 - val_loss: 1.6083 - val_accuracy: 0.2311\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.4636 - accuracy: 0.3102 - val_loss: 1.6096 - val_accuracy: 0.1954\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4939 - accuracy: 0.2962 - val_loss: 1.6096 - val_accuracy: 0.1954\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.4749 - accuracy: 0.3039 - val_loss: 1.6096 - val_accuracy: 0.1954\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4585 - accuracy: 0.2972 - val_loss: 1.6096 - val_accuracy: 0.1954\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.4488 - accuracy: 0.3128 - val_loss: 1.6097 - val_accuracy: 0.1954\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4685 - accuracy: 0.3087 - val_loss: 1.6097 - val_accuracy: 0.1954\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.4477 - accuracy: 0.3123 - val_loss: 1.6097 - val_accuracy: 0.2031\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4458 - accuracy: 0.3179 - val_loss: 1.6097 - val_accuracy: 0.1954\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4477 - accuracy: 0.3261 - val_loss: 1.6097 - val_accuracy: 0.1954\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4530 - accuracy: 0.3155 - val_loss: 1.6095 - val_accuracy: 0.1954\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4639 - accuracy: 0.3172 - val_loss: 1.6089 - val_accuracy: 0.1954\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4619 - accuracy: 0.3116 - val_loss: 1.6094 - val_accuracy: 0.1954\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4378 - accuracy: 0.3256 - val_loss: 1.6090 - val_accuracy: 0.2050\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4583 - accuracy: 0.3208 - val_loss: 1.6096 - val_accuracy: 0.1954\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4333 - accuracy: 0.3273 - val_loss: 1.6098 - val_accuracy: 0.1954\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.4314 - accuracy: 0.3312 - val_loss: 1.6098 - val_accuracy: 0.1954\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4270 - accuracy: 0.3362 - val_loss: 1.6095 - val_accuracy: 0.2012\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4479 - accuracy: 0.3396 - val_loss: 1.6096 - val_accuracy: 0.1963\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4340 - accuracy: 0.3304 - val_loss: 1.6097 - val_accuracy: 0.1954\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4123 - accuracy: 0.3304 - val_loss: 1.6099 - val_accuracy: 0.1954\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.4292 - accuracy: 0.3396 - val_loss: 1.6098 - val_accuracy: 0.1954\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4312 - accuracy: 0.3225 - val_loss: 1.6093 - val_accuracy: 0.1963\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4346 - accuracy: 0.3357 - val_loss: 1.6091 - val_accuracy: 0.1963\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4408 - accuracy: 0.3220 - val_loss: 1.6098 - val_accuracy: 0.1954\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4091 - accuracy: 0.3331 - val_loss: 1.6094 - val_accuracy: 0.1963\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3946 - accuracy: 0.3452 - val_loss: 1.6100 - val_accuracy: 0.1954\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4316 - accuracy: 0.3225 - val_loss: 1.6098 - val_accuracy: 0.1954\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4263 - accuracy: 0.3336 - val_loss: 1.6099 - val_accuracy: 0.1954\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4125 - accuracy: 0.3321 - val_loss: 1.6101 - val_accuracy: 0.1954\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4281 - accuracy: 0.3273 - val_loss: 1.6095 - val_accuracy: 0.1963\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4202 - accuracy: 0.3300 - val_loss: 1.6090 - val_accuracy: 0.1963\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3891 - accuracy: 0.3379 - val_loss: 1.6097 - val_accuracy: 0.1963\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4065 - accuracy: 0.3396 - val_loss: 1.6094 - val_accuracy: 0.1963\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4150 - accuracy: 0.3468 - val_loss: 1.6101 - val_accuracy: 0.1954\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3996 - accuracy: 0.3524 - val_loss: 1.6101 - val_accuracy: 0.2031\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4030 - accuracy: 0.3384 - val_loss: 1.6090 - val_accuracy: 0.2041\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.4060 - accuracy: 0.3394 - val_loss: 1.6102 - val_accuracy: 0.2031\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3894 - accuracy: 0.3589 - val_loss: 1.6098 - val_accuracy: 0.2031\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3842 - accuracy: 0.3575 - val_loss: 1.6085 - val_accuracy: 0.2041\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4095 - accuracy: 0.3355 - val_loss: 1.6098 - val_accuracy: 0.1954\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3861 - accuracy: 0.3439 - val_loss: 1.6092 - val_accuracy: 0.1963\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4113 - accuracy: 0.3324 - val_loss: 1.6097 - val_accuracy: 0.1954\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4048 - accuracy: 0.3541 - val_loss: 1.6091 - val_accuracy: 0.1954\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.4011 - accuracy: 0.3529 - val_loss: 1.6086 - val_accuracy: 0.2031\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3713 - accuracy: 0.3565 - val_loss: 1.6084 - val_accuracy: 0.2041\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3890 - accuracy: 0.3575 - val_loss: 1.6103 - val_accuracy: 0.2031\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3895 - accuracy: 0.3509 - val_loss: 1.6098 - val_accuracy: 0.2031\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3827 - accuracy: 0.3628 - val_loss: 1.6101 - val_accuracy: 0.2031\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3767 - accuracy: 0.3649 - val_loss: 1.6105 - val_accuracy: 0.2031\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3901 - accuracy: 0.3550 - val_loss: 1.6107 - val_accuracy: 0.2031\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3828 - accuracy: 0.3637 - val_loss: 1.6103 - val_accuracy: 0.2031\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3763 - accuracy: 0.3644 - val_loss: 1.6103 - val_accuracy: 0.2031\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3702 - accuracy: 0.3659 - val_loss: 1.6109 - val_accuracy: 0.2031\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3687 - accuracy: 0.3599 - val_loss: 1.6103 - val_accuracy: 0.2041\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3596 - accuracy: 0.3676 - val_loss: 1.6108 - val_accuracy: 0.2031\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3517 - accuracy: 0.3743 - val_loss: 1.6108 - val_accuracy: 0.2031\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3860 - accuracy: 0.3589 - val_loss: 1.6111 - val_accuracy: 0.2031\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3607 - accuracy: 0.3671 - val_loss: 1.6111 - val_accuracy: 0.2031\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3707 - accuracy: 0.3676 - val_loss: 1.6110 - val_accuracy: 0.2041\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3703 - accuracy: 0.3693 - val_loss: 1.6115 - val_accuracy: 0.2031\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3808 - accuracy: 0.3495 - val_loss: 1.6111 - val_accuracy: 0.2031\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3678 - accuracy: 0.3591 - val_loss: 1.6116 - val_accuracy: 0.2031\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3853 - accuracy: 0.3550 - val_loss: 1.6117 - val_accuracy: 0.2031\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3410 - accuracy: 0.3739 - val_loss: 1.6117 - val_accuracy: 0.2031\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3688 - accuracy: 0.3736 - val_loss: 1.6116 - val_accuracy: 0.2031\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3632 - accuracy: 0.3775 - val_loss: 1.6118 - val_accuracy: 0.2031\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3745 - accuracy: 0.3714 - val_loss: 1.6110 - val_accuracy: 0.2031\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3512 - accuracy: 0.3847 - val_loss: 1.6119 - val_accuracy: 0.2041\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3768 - accuracy: 0.3599 - val_loss: 1.6099 - val_accuracy: 0.2041\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3625 - accuracy: 0.3743 - val_loss: 1.6107 - val_accuracy: 0.2041\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3467 - accuracy: 0.3714 - val_loss: 1.6117 - val_accuracy: 0.2031\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3542 - accuracy: 0.3717 - val_loss: 1.6116 - val_accuracy: 0.2041\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3492 - accuracy: 0.3804 - val_loss: 1.6126 - val_accuracy: 0.2041\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3656 - accuracy: 0.3582 - val_loss: 1.6105 - val_accuracy: 0.2050\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3459 - accuracy: 0.3678 - val_loss: 1.6104 - val_accuracy: 0.2002\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3530 - accuracy: 0.3741 - val_loss: 1.6123 - val_accuracy: 0.2031\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3644 - accuracy: 0.3673 - val_loss: 1.6123 - val_accuracy: 0.2041\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3416 - accuracy: 0.3729 - val_loss: 1.6130 - val_accuracy: 0.2031\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3386 - accuracy: 0.3866 - val_loss: 1.6135 - val_accuracy: 0.2031\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3493 - accuracy: 0.3755 - val_loss: 1.6133 - val_accuracy: 0.2031\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3512 - accuracy: 0.3825 - val_loss: 1.6137 - val_accuracy: 0.2031\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3414 - accuracy: 0.3808 - val_loss: 1.6141 - val_accuracy: 0.2031\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3357 - accuracy: 0.3837 - val_loss: 1.6139 - val_accuracy: 0.2031\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3476 - accuracy: 0.3780 - val_loss: 1.6142 - val_accuracy: 0.2031\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3662 - accuracy: 0.3724 - val_loss: 1.6140 - val_accuracy: 0.2031\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3331 - accuracy: 0.3816 - val_loss: 1.6134 - val_accuracy: 0.2031\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3301 - accuracy: 0.3840 - val_loss: 1.6144 - val_accuracy: 0.2031\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3304 - accuracy: 0.3883 - val_loss: 1.6147 - val_accuracy: 0.2031\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3507 - accuracy: 0.3743 - val_loss: 1.6146 - val_accuracy: 0.2031\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3348 - accuracy: 0.3830 - val_loss: 1.6150 - val_accuracy: 0.2031\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3362 - accuracy: 0.3845 - val_loss: 1.6141 - val_accuracy: 0.2031\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3683 - accuracy: 0.3659 - val_loss: 1.6127 - val_accuracy: 0.2041\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3280 - accuracy: 0.3862 - val_loss: 1.6111 - val_accuracy: 0.2041\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3112 - accuracy: 0.3941 - val_loss: 1.6117 - val_accuracy: 0.2050\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3528 - accuracy: 0.3729 - val_loss: 1.6138 - val_accuracy: 0.2031\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3301 - accuracy: 0.3818 - val_loss: 1.6143 - val_accuracy: 0.2031\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3241 - accuracy: 0.3811 - val_loss: 1.6151 - val_accuracy: 0.2031\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3221 - accuracy: 0.3789 - val_loss: 1.6145 - val_accuracy: 0.2031\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3333 - accuracy: 0.3772 - val_loss: 1.6126 - val_accuracy: 0.2031\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3334 - accuracy: 0.3878 - val_loss: 1.6145 - val_accuracy: 0.2031\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3176 - accuracy: 0.3917 - val_loss: 1.6080 - val_accuracy: 0.2050\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3225 - accuracy: 0.3830 - val_loss: 1.6103 - val_accuracy: 0.2050\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3198 - accuracy: 0.3876 - val_loss: 1.6094 - val_accuracy: 0.2041\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3232 - accuracy: 0.3852 - val_loss: 1.5713 - val_accuracy: 0.2505\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3681 - accuracy: 0.3835 - val_loss: 1.6149 - val_accuracy: 0.2031\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3217 - accuracy: 0.3992 - val_loss: 1.6118 - val_accuracy: 0.2041\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3398 - accuracy: 0.3857 - val_loss: 1.6114 - val_accuracy: 0.2041\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3175 - accuracy: 0.3936 - val_loss: 1.6110 - val_accuracy: 0.2041\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3159 - accuracy: 0.3934 - val_loss: 1.6146 - val_accuracy: 0.2041\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3119 - accuracy: 0.3922 - val_loss: 1.6120 - val_accuracy: 0.2041\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2958 - accuracy: 0.3939 - val_loss: 1.6115 - val_accuracy: 0.2050\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3205 - accuracy: 0.3977 - val_loss: 1.6133 - val_accuracy: 0.2041\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3084 - accuracy: 0.3927 - val_loss: 1.6131 - val_accuracy: 0.2041\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3331 - accuracy: 0.3796 - val_loss: 1.6125 - val_accuracy: 0.2031\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3028 - accuracy: 0.3924 - val_loss: 1.6146 - val_accuracy: 0.2031\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2937 - accuracy: 0.4016 - val_loss: 1.6102 - val_accuracy: 0.2031\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3211 - accuracy: 0.3970 - val_loss: 1.6101 - val_accuracy: 0.2041\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3253 - accuracy: 0.4069 - val_loss: 1.6129 - val_accuracy: 0.2050\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3178 - accuracy: 0.3842 - val_loss: 1.5976 - val_accuracy: 0.2060\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3307 - accuracy: 0.3960 - val_loss: 1.6102 - val_accuracy: 0.2041\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2856 - accuracy: 0.4021 - val_loss: 1.6097 - val_accuracy: 0.2041\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3354 - accuracy: 0.3842 - val_loss: 1.6134 - val_accuracy: 0.2031\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2854 - accuracy: 0.3987 - val_loss: 1.6133 - val_accuracy: 0.2031\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3143 - accuracy: 0.3970 - val_loss: 1.6010 - val_accuracy: 0.2041\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2802 - accuracy: 0.4033 - val_loss: 1.6096 - val_accuracy: 0.2031\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2824 - accuracy: 0.4091 - val_loss: 1.6066 - val_accuracy: 0.2031\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3062 - accuracy: 0.3929 - val_loss: 1.6056 - val_accuracy: 0.2041\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3028 - accuracy: 0.4018 - val_loss: 1.6084 - val_accuracy: 0.2041\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2850 - accuracy: 0.4035 - val_loss: 1.6131 - val_accuracy: 0.2031\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2992 - accuracy: 0.4096 - val_loss: 1.6113 - val_accuracy: 0.2041\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2898 - accuracy: 0.4033 - val_loss: 1.6142 - val_accuracy: 0.2041\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3070 - accuracy: 0.4108 - val_loss: 1.6050 - val_accuracy: 0.2050\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3091 - accuracy: 0.3924 - val_loss: 1.6093 - val_accuracy: 0.2031\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3166 - accuracy: 0.3994 - val_loss: 1.6134 - val_accuracy: 0.2041\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2696 - accuracy: 0.3951 - val_loss: 1.6099 - val_accuracy: 0.2050\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2949 - accuracy: 0.3968 - val_loss: 1.6098 - val_accuracy: 0.2041\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2905 - accuracy: 0.4059 - val_loss: 1.6112 - val_accuracy: 0.2041\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2960 - accuracy: 0.4127 - val_loss: 1.6103 - val_accuracy: 0.2031\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2951 - accuracy: 0.4216 - val_loss: 1.6140 - val_accuracy: 0.2031\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2781 - accuracy: 0.4045 - val_loss: 1.6137 - val_accuracy: 0.2041\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2891 - accuracy: 0.4076 - val_loss: 1.6124 - val_accuracy: 0.2041\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.3078 - accuracy: 0.4035 - val_loss: 1.6177 - val_accuracy: 0.2031\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2653 - accuracy: 0.4100 - val_loss: 1.6106 - val_accuracy: 0.2031\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2969 - accuracy: 0.4279 - val_loss: 1.6030 - val_accuracy: 0.2060\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2654 - accuracy: 0.4221 - val_loss: 1.6078 - val_accuracy: 0.2031\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2644 - accuracy: 0.4132 - val_loss: 1.6122 - val_accuracy: 0.2041\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2843 - accuracy: 0.4105 - val_loss: 1.6159 - val_accuracy: 0.2031\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2747 - accuracy: 0.4134 - val_loss: 1.6144 - val_accuracy: 0.2041\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2794 - accuracy: 0.4093 - val_loss: 1.5859 - val_accuracy: 0.2186\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2957 - accuracy: 0.4062 - val_loss: 1.6107 - val_accuracy: 0.2031\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2949 - accuracy: 0.4117 - val_loss: 1.6046 - val_accuracy: 0.2060\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3006 - accuracy: 0.4120 - val_loss: 1.6019 - val_accuracy: 0.2060\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2676 - accuracy: 0.4178 - val_loss: 1.6127 - val_accuracy: 0.2041\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2575 - accuracy: 0.4216 - val_loss: 1.6064 - val_accuracy: 0.2031\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2851 - accuracy: 0.4120 - val_loss: 1.6193 - val_accuracy: 0.2031\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2577 - accuracy: 0.4129 - val_loss: 1.6141 - val_accuracy: 0.2060\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2636 - accuracy: 0.4038 - val_loss: 1.6085 - val_accuracy: 0.2050\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2446 - accuracy: 0.4303 - val_loss: 1.6003 - val_accuracy: 0.2118\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2763 - accuracy: 0.4137 - val_loss: 1.6177 - val_accuracy: 0.2031\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2555 - accuracy: 0.4209 - val_loss: 1.6140 - val_accuracy: 0.2031\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2668 - accuracy: 0.4091 - val_loss: 1.6061 - val_accuracy: 0.2002\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2913 - accuracy: 0.4023 - val_loss: 1.6082 - val_accuracy: 0.1992\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2603 - accuracy: 0.4221 - val_loss: 1.6117 - val_accuracy: 0.1992\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2669 - accuracy: 0.4223 - val_loss: 1.6025 - val_accuracy: 0.2002\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2503 - accuracy: 0.4076 - val_loss: 1.6169 - val_accuracy: 0.1992\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2634 - accuracy: 0.4163 - val_loss: 1.6142 - val_accuracy: 0.1983\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2445 - accuracy: 0.4219 - val_loss: 1.6165 - val_accuracy: 0.1992\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2768 - accuracy: 0.4206 - val_loss: 1.6124 - val_accuracy: 0.1992\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2364 - accuracy: 0.4308 - val_loss: 1.6025 - val_accuracy: 0.2070\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2822 - accuracy: 0.4192 - val_loss: 1.6073 - val_accuracy: 0.2050\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2800 - accuracy: 0.4202 - val_loss: 1.5617 - val_accuracy: 0.2505\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2620 - accuracy: 0.4216 - val_loss: 1.5519 - val_accuracy: 0.2698\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2411 - accuracy: 0.4320 - val_loss: 1.5756 - val_accuracy: 0.2350\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2325 - accuracy: 0.4291 - val_loss: 1.5913 - val_accuracy: 0.2186\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2733 - accuracy: 0.4262 - val_loss: 1.5652 - val_accuracy: 0.2534\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2490 - accuracy: 0.4334 - val_loss: 1.6043 - val_accuracy: 0.2070\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2625 - accuracy: 0.4291 - val_loss: 1.5609 - val_accuracy: 0.2524\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2424 - accuracy: 0.4257 - val_loss: 1.5327 - val_accuracy: 0.2959\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2395 - accuracy: 0.4397 - val_loss: 1.5976 - val_accuracy: 0.2070\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2613 - accuracy: 0.4199 - val_loss: 1.5695 - val_accuracy: 0.2427\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2478 - accuracy: 0.4356 - val_loss: 1.6048 - val_accuracy: 0.2070\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2455 - accuracy: 0.4351 - val_loss: 1.5938 - val_accuracy: 0.2137\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2394 - accuracy: 0.4325 - val_loss: 1.5831 - val_accuracy: 0.2186\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2223 - accuracy: 0.4392 - val_loss: 1.6016 - val_accuracy: 0.2050\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2404 - accuracy: 0.4315 - val_loss: 1.6099 - val_accuracy: 0.2070\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2509 - accuracy: 0.4298 - val_loss: 1.6091 - val_accuracy: 0.2070\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2843 - accuracy: 0.4231 - val_loss: 1.6117 - val_accuracy: 0.2041\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2835 - accuracy: 0.4243 - val_loss: 1.5870 - val_accuracy: 0.2621\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2072 - accuracy: 0.4436 - val_loss: 1.5497 - val_accuracy: 0.3162\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2271 - accuracy: 0.4387 - val_loss: 1.6005 - val_accuracy: 0.2176\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2574 - accuracy: 0.4257 - val_loss: 1.6169 - val_accuracy: 0.2031\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2723 - accuracy: 0.4149 - val_loss: 1.5951 - val_accuracy: 0.2176\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2365 - accuracy: 0.4226 - val_loss: 1.5879 - val_accuracy: 0.2137\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2259 - accuracy: 0.4301 - val_loss: 1.5818 - val_accuracy: 0.2195\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2264 - accuracy: 0.4491 - val_loss: 1.5766 - val_accuracy: 0.2282\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2528 - accuracy: 0.4245 - val_loss: 1.5515 - val_accuracy: 0.2553\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2577 - accuracy: 0.4206 - val_loss: 1.5685 - val_accuracy: 0.2350\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2529 - accuracy: 0.4339 - val_loss: 1.5104 - val_accuracy: 0.3124\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2292 - accuracy: 0.4356 - val_loss: 1.5798 - val_accuracy: 0.2282\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2300 - accuracy: 0.4329 - val_loss: 1.5932 - val_accuracy: 0.2128\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2488 - accuracy: 0.4339 - val_loss: 1.5903 - val_accuracy: 0.2108\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2460 - accuracy: 0.4303 - val_loss: 1.6101 - val_accuracy: 0.2050\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2424 - accuracy: 0.4320 - val_loss: 1.5834 - val_accuracy: 0.2186\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.2380 - accuracy: 0.4532 - val_loss: 1.5846 - val_accuracy: 0.2456\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2255 - accuracy: 0.4373 - val_loss: 1.5839 - val_accuracy: 0.2157\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.2077 - accuracy: 0.4486 - val_loss: 1.5945 - val_accuracy: 0.2089\n",
      "Epoch 241/500\n"
     ]
    }
   ],
   "source": [
    "efficient_model.optimizer.learning_rate = 0.001\n",
    "efficient_model.optimizer.momentum = 0.9\n",
    "with tf.device('/gpu:0'):\n",
    "    history = efficient_model.fit_generator(data_train,validation_data=data_val, epochs=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"Model Metrics\",(20,10))\n",
    "plt.title('model accuracy')\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"Model Metrics\",(20,10))\n",
    "plt.title('model accuracy')\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_model.save('../model/saved/efficient_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7575d3b4693a120f9db1d690d5dca1c64b6c1eb8514f8cd44a178527d835c61f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
