{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pair(object):\n",
    "    def __init__(self,data):\n",
    "        x, y = data\n",
    "        self.x, self.y = np.array(x), np.array(y)\n",
    "\n",
    "    def decode_img(self, img):\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        return img\n",
    "\n",
    "    def get_pairs(self):\n",
    "        x, y = self.x, self.y\n",
    "        pairs, labels = self.makePairs(len(np.unique(y)))\n",
    "        element_1, element_2 = tf.data.Dataset.from_tensor_slices(pairs[:, 0]), tf.data.Dataset.from_tensor_slices(pairs[:, 1])\n",
    "        labels = tf.data.Dataset.from_tensor_slices(labels)\n",
    "        return (element_1, element_2, labels)\n",
    "\n",
    "    def makePairs(self, num_classes):\n",
    "        num_classes = num_classes\n",
    "        x, y = self.x, self.y\n",
    "        digit_indices = [np.where(y == i)[0] for i in range(num_classes)]\n",
    "\n",
    "        pairs = list()\n",
    "        labels = list()\n",
    "\n",
    "        for idx1 in range(len(x)):\n",
    "            x1 = x[idx1]\n",
    "            label1 = y[idx1]\n",
    "            idx2 = random.choice(digit_indices[label1])\n",
    "            x2 = x[idx2]\n",
    "            \n",
    "            labels += list([1])\n",
    "            pairs += [[x1, x2]]\n",
    "\n",
    "            label2 = random.randint(0, num_classes-1)\n",
    "            while label2 == label1:\n",
    "                label2 = random.randint(0, num_classes-1)\n",
    "\n",
    "            idx2 = random.choice(digit_indices[label2])\n",
    "            x2 = x[idx2]\n",
    "            \n",
    "            labels += list([0])\n",
    "            pairs += [[x1, x2]]\n",
    "        \n",
    "        return np.array(pairs), np.array(labels)\n",
    "\n",
    "class Augment(object):\n",
    "\n",
    "    def rotate_img(img):\n",
    "        img = tf.keras.layers.RandomRotation(0.2)(img)\n",
    "        return img\n",
    "    \n",
    "    def zoom_img(img):\n",
    "        img = tf.keras.layers.RandomZoom(0.5)(img)\n",
    "        return img\n",
    "\n",
    "    def shift_img(img):\n",
    "        img = tf.keras.layers.RandomShift(0.5)(img)\n",
    "        return img\n",
    "\n",
    "    def flip_img(img):\n",
    "        img = tf.keras.layers.RandomFlip()(img)\n",
    "        return img\n",
    "\n",
    "    def shear_img(img):\n",
    "        img = tf.keras.preprocessing.image.random_shear(img, 0.2)\n",
    "        return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_for_siamese(DATA_DIR = \"C:\\\\Users\\\\aeternum\\\\Documents\\\\GitHub\\\\Gesture-Recognition\\\\my_robot\\\\python_scripts\\\\data\"):\n",
    "\n",
    "    # DATA_DIR = 'data'\n",
    "    IMAGE_DIR = f'{DATA_DIR}\\\\gestures'\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Map paths to images\n",
    "\n",
    "    def augment_pairs(image_data_1,image_data_2,labels,augmentation_config):\n",
    "\n",
    "        augmented_image_data_1 = image_data_1\n",
    "        augmented_image_data_2 = image_data_2\n",
    "        augmented_labels = labels\n",
    "\n",
    "        if \"rotation_range\" in augmentation_config:\n",
    "            rotated_1 = image_data_1.map(Augment.rotate_img)\n",
    "            rotated_2 = image_data_2.map(Augment.rotate_img)\n",
    "\n",
    "            augmented_image_data_1 = augmented_image_data_1.concatenate(rotated_1)\n",
    "            augmented_image_data_2 = augmented_image_data_2.concatenate(rotated_2)\n",
    "            augmented_labels = augmented_labels.concatenate(labels)\n",
    "\n",
    "        if \"width_shift_range\" in augmentation_config:\n",
    "            w_shifted_1 = image_data_1.map(Augment.shift_img)\n",
    "            w_shifted_2 = image_data_2.map(Augment.shift_img)\n",
    "\n",
    "            augmented_image_data_1 = augmented_image_data_1.concatenate(w_shifted_1)\n",
    "            augmented_image_data_2 = augmented_image_data_2.concatenate(w_shifted_2)\n",
    "            augmented_labels = augmented_labels.concatenate(labels)\n",
    "\n",
    "        if \"height_shift_range\" in augmentation_config:\n",
    "            h_shifted_1 = image_data_1.map(Augment.shift_img)\n",
    "            h_shifted_2 = image_data_2.map(Augment.shift_img)\n",
    "\n",
    "            augmented_image_data_1 = augmented_image_data_1.concatenate(h_shifted_1)\n",
    "            augmented_image_data_2 = augmented_image_data_2.concatenate(h_shifted_2)\n",
    "            augmented_labels = augmented_labels.concatenate(labels)\n",
    "\n",
    "        if \"zoom_range\" in augmentation_config:\n",
    "            zoomed_1 = image_data_1.map(Augment.zoom_img)\n",
    "            zoomed_2 = image_data_2.map(Augment.zoom_img)\n",
    "\n",
    "            augmented_image_data_1 = augmented_image_data_1.concatenate(zoomed_1)\n",
    "            augmented_image_data_2 = augmented_image_data_2.concatenate(zoomed_2)\n",
    "            augmented_labels = augmented_labels.concatenate(labels)\n",
    "\n",
    "        if \"flip_horizontal\" in augmentation_config:\n",
    "            flipped_1 = image_data_1.map(Augment.flip_img)\n",
    "            flipped_2 = image_data_2.map(Augment.flip_img)\n",
    "\n",
    "            augmented_image_data_1 = augmented_image_data_1.concatenate(flipped_1)\n",
    "            augmented_image_data_2 = augmented_image_data_2.concatenate(flipped_2)\n",
    "            augmented_labels = augmented_labels.concatenate(labels)\n",
    "\n",
    "        if \"shear_range\" in augmentation_config:\n",
    "            sheared_1 = image_data_1.map(Augment.shear_img)\n",
    "            sheared_2 = image_data_2.map(Augment.shear_img)\n",
    "\n",
    "            augmented_image_data_1 = augmented_image_data_1.concatenate(sheared_1)\n",
    "            augmented_image_data_2 = augmented_image_data_2.concatenate(sheared_2)\n",
    "            augmented_labels = augmented_labels.concatenate(labels)\n",
    "\n",
    "        return (augmented_image_data_1,augmented_image_data_2,augmented_labels)\n",
    "\n",
    "\n",
    "    def decode_img(img):\n",
    "        img = tf.io.read_file(img)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, (224, 224))\n",
    "        # img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        return img\n",
    "\n",
    "    \n",
    "    for folder in os.listdir(IMAGE_DIR):\n",
    "        for image in os.listdir(f'{IMAGE_DIR}/{folder}'):\n",
    "            images.append(f'{IMAGE_DIR}/{folder}/{image}')\n",
    "            labels.append(int(folder))\n",
    "\n",
    "    pair_generator = Pair((images, labels))\n",
    "    element_set_1, element_set_2, pair_labels =  pair_generator.get_pairs()\n",
    "\n",
    "    # Evaluate the dataset\n",
    "\n",
    "    element_set_1 = element_set_1.map(decode_img)\n",
    "    element_set_2 = element_set_2.map(decode_img)\n",
    "    pair_labels = pair_labels.map(lambda x: tf.one_hot(x, 2))\n",
    "\n",
    "    return (element_set_1, element_set_2, pair_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1,i2,l = generate_data_for_siamese()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Augment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_for_classifier(DATA_DIR, batch_size = 32, target_size = (128,128), augmentation_config = {\n",
    "    \"rotation_range\":30,\n",
    "    \"width_shift_range\":0.2,\n",
    "    \"height_shift_range\":0.2,\n",
    "    \"shear_range\":0.2,\n",
    "    \"zoom_range\":0.5,\n",
    "    \"horizontal_flip\":False\n",
    "}):\n",
    "\n",
    "    # DATA_DIR = 'data'\n",
    "    IMAGE_DIR = f'{DATA_DIR}/gestures'\n",
    "\n",
    "    image_generator = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=augmentation_config['rotation_range'],\n",
    "        width_shift_range=augmentation_config['width_shift_range'],\n",
    "        height_shift_range=augmentation_config['height_shift_range'],\n",
    "        shear_range=augmentation_config['shear_range'],\n",
    "        zoom_range=augmentation_config['zoom_range'],\n",
    "        horizontal_flip=augmentation_config['horizontal_flip'],\n",
    "        )\n",
    "    image_data = image_generator.flow_from_directory(\n",
    "        IMAGE_DIR,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "    )\n",
    "\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "data = generate_data_for_classifier(\"C:/Users/aeternum/Documents/GitHub/Gesture-Recognition/my_robot/python_scripts/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128,128,3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 126, 126, 32)\n",
      "(None, 63, 63, 32)\n",
      "(None, 61, 61, 64)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('gest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4b38242fd521d331e5e27e2fd176157716eb15b68a54c6a842baebd0130fefc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
